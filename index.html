<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="https://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
    google.load("jquery", "1.3.2");
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6YQVECV1ZB"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-6YQVECV1ZB');
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.0.0/jquery.min.js"></script>

<!-- jQuery Modal -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.css" />

<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
    rel='stylesheet' type='text/css'>

<div class="topnav" id="myTopnav">
    <a href="http://infosec.pusan.ac.kr/"><img width="100%" src="assets/logo/infosec_logo.png"></a>
    <a href="https://www.smartm2m.co.kr/"><img width="100%" src="assets/logo/smartm2m_blk_logo.png"></a>
    <a href="https://add.re.kr/"><img width="100%" src="assets/logo/add_logo.png"></a>
</div>

<head>
    <title>ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion</title>
    <meta property="og:description"
        content="ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion" />
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>


<body>
    <div class="container">

        <div id="avs" class="modal">
            <p>Available soon...</p>
        </div>

        <div class="paper-title">
            <h1>ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion</h1>
            <h2>ICCV 2023</h2>
        </div>

        <div id="authors">
            <div class="author-row">
                <div class="col-3 text-center">
                    <a href="https://www.linkedin.com/in/naufal-suryanto/">Naufal Suryanto</a>
                    <sup>1</sup>
                </div>
                <div>
                    <div class="col-3 text-center">
                        <a href="https://scholar.google.co.kr/citations?user=DXb797cAAAAJ">Youngsu Kim</a>
                        <sup>1,2</sup>
                    </div>
                    <div>
                        <div class="col-3 text-center">
                            <a href="https://scholar.google.co.id/citations?user=S8lwCEUAAAAJ">Harashta Tatimma
                                Larasati</a>
                            <sup>1</sup>
                        </div>
                        <div>
                            <div class="col-3 text-center">
                                <a href="https://scholar.google.co.kr/citations?user=GeQi_D4AAAAJ">Hyoeun Kang</a>
                                <sup>1,2</sup>
                            </div>
                        </div>
                        <div>
                            <div class="col-3 text-center">
                                <a href="https://scholar.google.com/citations?user=UptzPYsAAAAJ">Thi-Thu-Huong Le</a>
                                <sup>1</sup>
                            </div>
                        </div>
                        <div>
                            <div class="col-3 text-center">
                                Yoonyoung Hong
                                <sup>1</sup>
                            </div>
                        </div>
                        <div>
                            <div class="col-3 text-center">
                                <a href="https://scholar.google.co.kr/citations?user=mDxJj2AAAAAJ">Hunmin Yang</a>
                                <sup>3</sup>
                            </div>
                        </div>
                        <div>
                            <div class="col-3 text-center">
                                <a href="https://ieeexplore.ieee.org/author/37088566336">Se-Yoon Oh</a>
                                <sup>3</sup>
                            </div>
                        </div>
                        <div>
                            <div class="col-3 text-center">
                                <a href="https://ieeexplore.ieee.org/author/37082911200"> Howon Kim</a>
                                <sup>1,2,*</sup>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="affil-row">
                <div class="col-3 text-center">
                    <sup>1</sup>
                    Pusan National University
                </div>
                <div class="col-3 text-center">
                    <sup>2</sup>
                    SmartM2M
                </div>
                <div class="col-3 text-center">
                    <sup>3</sup>
                    Agency for Defense Development
                </div>
            </div>
        </div>
        <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="supp-btn"
                    href="https://openaccess.thecvf.com/content/ICCV2023/html/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.html">
                    <span class="material-icons"> description </span>
                    Paper
                </a>
                <a class="supp-btn" href="./bib.txt">
                    <span class="material-icons"> school </span>
                    BibTeX
                </a>
                <a class="supp-btn" href="./assets/poster/ACTIVE-ICCV2023-Poster-Final-Resized.pdf">
                    <span class="material-icons"> image </span>
                    Poster
                </a>
                <a class="supp-btn" href="https://www.youtube.com/watch?v=Za3aquQ3xiI">
                    <span class="material-icons"> movie </span>
                    Presentation Video
                </a>
            </div>
        </div>
        <section id="abstract">
            <h2>Abstract</h2>
            <hr>
            <p>
                Adversarial camouflage has garnered attention for its ability to attack object detectors from any
                viewpoint by covering the entire object's surface. However, universality and robustness in existing
                methods often fall short as the transferability aspect is often overlooked, thus restricting their
                application only to a specific target with limited performance. To address these challenges, we present
                Adversarial Camouflage for Transferable and Intensive Vehicle Evasion (ACTIVE), a state-of-the-art
                physical camouflage attack framework designed to generate universal and robust adversarial camouflage
                capable of concealing any 3D vehicle from detectors. Our framework incorporates innovative techniques to
                enhance universality and robustness, including a refined texture rendering that enables common texture
                application to different vehicles without being constrained to a specific texture map, a novel stealth
                loss that renders the vehicle undetectable, and a smooth and camouflage loss to enhance the naturalness
                of the adversarial camouflage. Our extensive experiments on 15 different models show that ACTIVE
                consistently outperforms existing works on various public detectors, including the latest YOLOv7.
                Notably, our universality evaluations reveal promising transferability to other vehicle classes, tasks
                (segmentation models), and the real world, not just other vehicles.
            </p>

            <table>
                <thead>
                    <tr>
                        <th align="center">Photo-Realistic Simulation Demo</th>
                        <th align="center">Real World Demo</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td align="center">
                            <video class="centered" width="95%" muted loop autoplay>
                                <source src="assets/video/demo/photo-rendering-demo.webm" type="video/webm"
                                    alter="real Video">
                                Your browser does not support the video tag.
                            </video>
                        </td>
                        <td align="center">
                            <video class="centered" width="95%" muted loop autoplay>
                                <source src="assets/video/demo/realworld.webm" type="video/webm" alter="photo Video">
                                Your browser does not support the video tag.
                            </video>
                        </td>
                    </tr>
                </tbody>
            </table>


        </section>

        <br>
        <br>

        <section id="results">
            <h2>ACTIVE Framework</h2>
            <hr>
            <p>
                To generate universal and robust adversarial camouflage, we propose the <b>ACTIVE framework</b>,
                comprimising: (1) <b>Triplanar Mapping</b> with <b>Neural Texture Renderer</b>, (2) <b>Stealth Loss</b>,
                (3) <b>Random Output Augmentation</b>, and (4) <b>Smooth and Camouflage Loss</b>. The overall framework
                is illustrated in following figure:
                <!-- To generate universal and robust adversarial camouflage, we propose the <b>ACTIVE framework</b>, which
                employs an object-independent texture mapping with a neural renderer, a new attack loss function to
                cause the vehicle undetectable, random output augmentation that enhance the texture robustness by
                digital transformation, smooth and camouflage loss to enhance the texture naturalness. The overall
                framework is illustrated in following figure. -->

            </p>
            <section id="teaser">
                <figure style="width: 100%;">
                    <a href="assets/img/framework.jpg">
                        <img width="100%" style="background-color:white" src="assets/img/framework.jpg">
                    </a>
                    <p class="caption" style="margin-bottom: 1px;">
                        <b> Adversarial Camouflage for Transferable and Intensive Vehicle Evasion(ACTIVE) </b>
                        is a state-of-the-art physical camouflage attack framework designed to generate universal and
                        robust adversarial camouflage capable of concealing any 3D vehicle from detectors. It enhances
                        the robustness, universality, and naturalness of adversarial camouflage compared to previous
                        methods.
                    </p>
                </figure>
            </section>

            <br>
            <br>

            <h2>Triplanar Mapping (TPM)</h2>
            <hr>
            <div class="flex-row">
                <div class="flex-row" style="width: 45%;">
                    <p>
                        We present the utilization of <b>triplanar mapping</b>, a texture mapping approach that applies
                        textures to objects by projecting them from <b>three directions</b> based on their <b>surface
                            coordinates and normals</b>, which can be derived from the depth image and camera parameter.
                        This technique proves highly advantageous for generating <b>object-independent adversarial
                            textures</b>, as it doesn't depend on object-specific texture maps. Consequently, we can
                        optimize a single adversarial camouflage that works universally across multiple vehicles,
                        rendering our attack <b>instance-agnostic</b>.
                        <!-- We use multiple 3D vehiclemodels instead of one to increase universality.
                        We collectmultiple vehicle datasets from Unreal Engine and train asingle DTN
                        model to enable
                        rendering for various vehicles.
                        We verify that our ACTIVE can generate arobust universal attack pattern for
                        various vehicles.
                        This isadvantageous compared to the previous works that utilizelegacy texture
                        mapping on neural
                        rendering,
                        which cannotgenerate a universal adversarial camouflage due to mapping being
                        dependent on the 3D
                        object. -->
                    </p>
                </div>
                <figure style="width: 50%; ">
                    <video class="centered" width="100%" controls muted loop autoplay>
                        <source src="assets/video/demo/univer-demo.webm" type="video/webm" alter="real Video">
                        Your browser does not support the video tag.
                    </video>
                </figure>
            </div>
            <div class="flex-row">
                <p>Figure: Triplanar Mapping pipeline and mechanism.</p>
            </div>
            <div class="flex-row">
                <figure style="width: 50%;text-align: center; ">
                    <a href="assets/img/triplanar_mapping_1.jpg">
                        <img width="95%" style="background-color:white" src="assets/img/triplanar_mapping_1.jpg">
                    </a>
                    <p class="caption" style="margin-bottom: 1px; text-align: center;">
                        (a) Triplanar mapping pipeline.
                    </p>
                </figure>
                <figure style="width: 50%; ">
                    <a href="assets/img/triplanar_mapping_2.jpg">
                        <img width="95%" style="background-color:white" src="assets/img/triplanar_mapping_2.jpg">
                    </a>
                    <p class="caption" style="margin-bottom: 1px; text-align: center;">
                        (b) Triplanar mapping mechanism.
                    </p>
                </figure>
            </div>

            <br>
            <br>

            <h2>Neural Texture Renderer (NTR)</h2>
            <hr>
            <p>We present <b>Neural Texture Renderer (NTR)</b>, the improvement of <a
                    href="https://openaccess.thecvf.com/content/CVPR2022/html/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.html">
                    Differentiable Transformation Network (DTN) by our previous work</a> in the term of
                <i>efficiency</i>.
                While it effectively synergizes with our triplanar mapping approach to apply physical transformations
                from the reference image, we identified redundancies within DTN, specifically in the
                Transformation Features (TF) and the training process. The improvement of NTR over DTN is illustrated as
                follows:
            </p>
            <p>
                <b>Redundancy in Transformation Features</b>: <a
                    href="https://openaccess.thecvf.com/content/CVPR2022/html/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.html">
                    DTN</a>, employs four Transformation Features
                (TF): TF Subtractor + ReLU, TF Adder, TF Multiplier, and TF Final Adder, intended to encompass basic
                transformations. We theorize that the initial two layers are redundant, with the last two layers
                sufficient to encode TF. Thus, our final TF, mimic to weights and biases in Neural Network design,
                comprises only TF Multiplier and TF Final Adder. Our NTR architecture, illustrated in Fig. <a
                    href="assets/img/NTR_Architecture2.jpg">(a)</a>.
            </p>
            <p>
                <b>Redundancy in Dataset</b>: <a
                    href="https://openaccess.thecvf.com/content/CVPR2022/html/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.html">
                    DTN</a>'s training dataset encompasses 50 flat random color textures. We
                contend this approach is inefficient, especially when training the network for multiple objects. To
                foster generalization of colors, we propose training the network with eight boundary colors in RGB space
                and gray [128, 128, 128] as the reference color. These eight boundary colors include primary (red,
                green, blue), secondary (magenta, yellow, cyan), white, and black, as depicted in Fig. <a
                    href="assets/img/ntr_boundary_colors.jpg">(b)</a>.
            </p>
            <div class="flex-row">
                <figure style="width: 70%;text-align: center; ">
                    <a href="assets/img/NTR_Architecture2.jpg">
                        <img width="95%" style="background-color:white" src="assets/img/NTR_Architecture2.jpg">
                    </a>
                    <p class="caption" style="margin-bottom: 1px; text-align: center;">
                        (a) Our Implemented NTR Architecture.
                    </p>
                </figure>
                <figure style="width: 30%;">
                    <br>
                    <br>
                    <a href="assets/img/ntr_boundary_colors.jpg">
                        <img width="95%" style="background-color:white" src="assets/img/ntr_boundary_colors.jpg">
                    </a>
                    <br>
                    <p class="caption" style="margin-bottom: 1px; text-align: center;">
                        (b) Selected Boundary Colors in RGB Space
                    </p>
                </figure>
            </div>

            <br>
            <br>

            <h2>Stealth Loss</h2>
            <hr>
            <p> We propose <b>stealth loss</b> a novel attack loss function to make the object <b>undetectable</b>. The
                loss function is designed to minimize <b>both</b> the <b>objectness score</b> and the <b>maximum
                    confidence score across all classes</b> of <b>valid detection</b> (greater than the IOU
                threshold), making our attack class-agnostic. This approach not only leads to misclassification but also
                considers the possibility of the bounding box being empty, providing a more comprehensive adversarial
                influence.
            </p>
            <div class="flex-row">
                <figure style="width: 50%;text-align: center; ">
                    <a href="assets/img/active_cls_loss_sample.png">
                        <img width="95%" style="background-color:white" src="assets/img/active_cls_loss_sample.png">
                    </a>
                    <p class="caption" style="margin-bottom: 1px; text-align: center;">
                        (a) Texture optimized by <a
                            href="https://openaccess.thecvf.com/content/CVPR2022/html/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.html">
                            DTA's</a> L_atk. The cars are <b>missclassified</b>.
                    </p>
                </figure>
                <figure style="width: 50%; ">
                    <a href="assets/img/active_stealth_loss_sample.png">
                        <img width="95%" style="background-color:white" src="assets/img/active_stealth_loss_sample.png">
                    </a>
                    <p class="caption" style="margin-bottom: 1px; text-align: center;">
                        (b) Texture optimized by <b>Stealth Loss</b>. The cars are <b>undetected</b>.
                    </p>
                </figure>
            </div>


            <br>
            <br>

            <h2>Random Output Augmentation (ROA)</h2>
            <hr>
            <p>We introduce the <b>ROA</b> module to enhance texture robustness through diverse <b>digital
                    transformations</b> (i.e., <a href="https://arxiv.org/abs/1707.07397">EOT</a>). This module takes
                the output of NTR, which is the adversarial example, and augments it by applying random transformations
                like scaling, translation, brightness, and contrast. While NTR offers robustness against <i>physical
                    transformations</i>, ROA adds a layer of robustness through <i>digital transformations</i>,
                simulating real-world changes to a certain extent. Notably,
                this consideration of digital transformations is often absent in conventional adversarial camouflage
                methods.
            </p>
            <figure style="width: 100%;">
                <a href="assets/img/roa_ilustration.png">
                    <img width="100%" class="center" src="assets/img/roa_ilustration.png"
                        style="background-color:white;" />
                </a>
                <p class="caption" style="margin-bottom: 1px;">
                    Ilustration of applying Random Output Augmentation (ROA) to the output of NTR.
                    ROA applies random transformation to enhance the robustness of the adversarial camouflage by
                    simulating real-world changes.
                </p>
            </figure>


            <br>
            <br>

            <h2>Smooth and Camouflage Loss</h2>
            <hr>
            <p>
                We employ a <b>smooth loss</b> (i.e., <a href="https://arxiv.org/abs/1412.0035">Total Variation (TV)</a>
                loss)
                to enhance the texture's smoothness anda <b>camouflage loss</b> to achieve adversarial camouflage,
                encouraging texture-background similarity. The smooth loss enhances naturalness, while the camouflage
                loss facilitates seamless blending with thebackground, rendering the vehicle less imperceptible to human
                observers. Both losses enhance the natural appearance of the adversarial camouflage. Our study shows
                that omitting smooth loss outputs a rough texture, whereas excluding camouflage loss makes it more
                colorful and bright.
                <!-- We utilize a smooth loss (i.e., Total Variation (TV) loss) that improves the smoothness of the generated
                texture, and the camouflage loss to acquire the adversarial camouflage, which encourages the texture to
                be similar to the background. The smooth loss enhances the naturalness of the adversarial camouflage,
                while the camouflage loss is designed to make the adversarial camouflage blend in with the background,
                making the vehicle invisible to human observer. Both losses enhance the naturalness of the adversarial
                camouflage. -->

                <!-- We utilize a smooth loss (i.e., Total Variation (TV) loss) and camouflage loss to improve texture's
                naturalness for human vision as well as computer vision. The smooth loss encourages the texture to be
                smooth, while the camouflage loss encourages the texture to be similar to the background. -->
            </p>
            <figure style="width: 100%;">
                <a href="assets/img/smooth_camouflage_texture_and_rendered.png">
                    <img width="100%" class="center" src="assets/img/smooth_camouflage_texture_and_rendered.png"
                        style="background-color:white;" />
                </a>
                <p class="caption" style="margin-bottom: 1px;">

                </p>
            </figure>


            <br>
            <br>

            <h2>Evaluation Results</h2>
            <hr>
            <p>

            </p>

            <h3>Robustness Evaluation</h3>
            <hr>
            <p style="text-align: center;">[Click the link to show sample demo videos]</p>
            <h4><a href="evaluation/transferbility/yolov3_7_5m_15p.html">Target: YOLOv3 | Camera: 7.5m
                    Distance, 15° Pitch,
                    360°
                    Rotation</a></h4>
            <h4><a href="evaluation/transferbility/ssd_10m_15p.html">Target: SSD | Camera: 10m
                    Distance, 15°
                    Pitch, 360°
                    Rotation</a></h4>
            <h4><a href="evaluation/transferbility/fasterrcnn_10m_30p.html">Target: Faster-RCNN |
                    Camera: 10m Distance, 30°
                    Pitch, 360°
                    Rotation</a></h4>
            <h4><a href="evaluation/transferbility/mask_rcnn_12_5m_30p.html">Target: Mask-RCNN | Camera:
                    12.5m Distance, 30°
                    Pitch,
                    360° Rotation</a></h4>



            <h3>Universality Evaluation</h3>
            <hr>
            <p style="text-align: center;">[Click the link to show sample demo videos]</p>
            <h4><a href="evaluation/universality/yolov7_7_5m_15p.html">Target: YOLOv7 | Camera: 7.5m
                    Distance, 15° Pitch,
                    360°
                    Rotation</a></h4>
            <h4><a href="evaluation/universality/dynamic_rcnn_10m_45p.html">Target: Dynamic R-CNN |
                    Camera: 10m Distance,
                    45° Pitch,
                    360°
                    Rotation</a></h4>
            <h4><a href="evaluation/universality/ptv_12_5m_30p.html">Target: PTV | Camera: 12.5m Distance,
                    30° Pitch,
                    360° Rotation</a></h4>

            <h4><a href="evaluation/universality/ddetr_12_5m_15p.html">Target: Deformable-DETR | Camera:
                    12.5m Distance,
                    15° Pitch,
                    360° Rotation</a></h4>


            <h3>Evaluation of Transferability to Segmentation Task</h3>
            <hr>
            <p style="text-align: center;">[Click the link to show sample demo videos]</p>
            <h4><a href="evaluation/segmentation/axialdeeplab_ccc_10m_15p.html">Target: Axial-DeepLab |
                    Camera: 10m
                    Distance, 15° Pitch, 360°
                    Rotation</a></h4>

            <h3>Real-World Evaluation</h3>
            <hr>

            <p style="text-align: center;">[Click the link to show sample image]</p>
            <h4><a href="evaluation/real/real_evaluation.html">Target: YOLOv3 | Camera: [Near, Medium,
                    Far] Distance, [Low,
                    High] Pitch, 360°
                    Rotation</a></h4>
            <div class="flex-row">
                <figure style="width: 50%;">
                    <video id="real_normal" class="centered" width="95%" controls muted loop>
                        <source src="assets/video/real/360_rotation_normal_detected_blurring 5x.webm" type="video/webm">
                        Your browser does not support the video tag.
                    </video>
                </figure>
                <figure style="width: 50%;">
                    <video id="real_attack" class="centered" width="95%" controls muted loop>
                        <source src="assets/video/real/360_rotation_attack_5x.webm" type="video/webm">
                        Your browser does not support the video tag.
                    </video>
                </figure>
            </div>
            <section id="teaser">
                <figure style="width: 100%;">
                    <a href="assets/img/best_result.jpg">
                        <img width="100%" style="background-color:white" src="assets/img/best_result.jpg">
                    </a>
                </figure>
            </section>

        </section>
        <section id="bibtex">
            <h2>Citation</h2>
            <hr>
            <pre><code>
    @InProceedings{Suryanto_2023_ICCV,
        author = {Suryanto, Naufal and Kim, Yongsu and Larasati, Harashta Tatimma and Kang, Hyoeun and 
            Le, Thi-Thu-Huong and Hong, Yoonyoung and Yang, Hunmin and Oh, Se-Yoon and Kim, Howon},
        title = {ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust
            Vehicle Evasion},
        booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
        month = {October},
        year = {2023},
        pages = {4305-4314}
    }
            </code></pre>
        </section>

        <br />
        <section id="paper">
            <h2>Paper</h2>
            <hr>
            <div class="flex-row">
                <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                    <a href="assets/img/active_preview.PNG"><img class="screenshot"
                            src="assets/img/active_preview.PNG"></a>
                </div>
                <div style="width: 50%">
                    <p><b></b></p>
                    <p>
                        <b>ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle
                            Evasion</b>
                    </p>
                    <p>
                        Naufal Suryanto, Yongsu Kim, Harashta Tatimma Larasati, Hyoeun Kang, Thi-Thu-Huong Le,
                        Yoonyoung Hong, Hunmin Yang, Se-Yoon Oh, Howon Kim
                    </p>
                    <div><span class="material-icons"> description </span>
                        <a
                            href="https://openaccess.thecvf.com/content/ICCV2023/papers/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.pdf">
                            Paper
                        </a>
                    </div>
                    <div><span class="material-icons"> note_add </span>
                        <a
                            href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Suryanto_ACTIVE_Towards_Highly_ICCV_2023_supplemental.pdf">
                            Supplementary
                        </a>
                    </div>
                    <div><span class="material-icons"> description </span>
                        <a href="https://arxiv.org/abs/2308.07009">
                            ArXiv
                        </a>
                    </div>
                    <div><span class="material-icons"> school </span>
                        <a href="./bib.txt">
                            BibTeX
                        </a>
                    </div>
                    <div><span class="material-icons"> code </span>
                        <a href="#">
                            Materials and Docs ( Available soon )
                        </a>
                    </div>
                </div>
            </div>
        </section>
    </div>
    <!-- <script src="script.js"></script> -->
</body>

</html>